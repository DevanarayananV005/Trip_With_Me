<!DOCTYPE html>
<html>
<head>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    <title>Photo Capture</title>
    <style>
        #videoContainer {
            position: relative;
            width: 640px;
            height: 480px;
        }
        #video {
            width: 100%;
            height: 100%;
        }
        #faceFrame {
            position: absolute;
            border: 2px solid red;
            top: 20%;
            left: 20%;
            width: 60%;
            height: 60%;
            z-index: 2;
        }
        #faceStatus {
            position: absolute;
            bottom: 10px;
            left: 10px;
            z-index: 2;
            color: red;
            font-weight: bold;
        }
        .allitem {
            margin-left: 500px;
            margin-top: 30px;
            background: rgba(81, 203, 219, 0.43);
            border-radius: 16px;
            box-shadow: 0 4px 30px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(6.7px);
            -webkit-backdrop-filter: blur(6.7px);
            border: 1px solid rgba(81, 203, 219, 0.3);
            width: 650px;
            height: 700px;

        }
        body {
            background-image: url('static/images/aes7.jpg'); /* Path to your background image */
            background-repeat: no-repeat;  /* Prevent the background from repeating */
            background-size: cover;        /* Scale the background image to cover the entire element */
            background-position: center center; /* Center the background image */
            background-attachment: fixed;  /* Fix the background image to the viewport */
        }
    </style>
</head>
<body>
    <h1 style="color:white;font-family: 'Times New Roman', Times, serif;">TRIP WITH ME</h1>
    <div class="allitem">
        <center>
        <h1 align="center" style="font-family:georgia,garamond,serif;color:black;"> PROFILE PICTURE</h1><br>
        <p style="color:blue;">Align your head and shoulders in the Red square todetct yoyr face. This photo will be used as your profile picture!!</p> <b>Click the capture button when it shows "Face detected".</b>
    <div id="videoContainer" style="height: 400px;width: 400px;">
        <video id="video" autoplay playsinline></video>
        <div id="faceFrame"></div>
        <div id="faceStatus">Face not detected</div>
    </div>
    <button id="captureButton" style="" class="btn btn-outline-light" disabled>Capture</button>
</center>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>

    <script>
        const video = document.getElementById('video');
        const faceFrame = document.getElementById('faceFrame');
        const faceStatus = document.getElementById('faceStatus');
        const captureButton = document.getElementById('captureButton');

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { width: 640, height: 480 },
                audio: false
            });
            video.srcObject = stream;
        }

        async function detectFaces() {
            const model = await blazeface.load();
            const context = document.createElement('canvas').getContext('2d');
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            context.canvas.width = canvas.width;
            context.canvas.height = canvas.height;

            setInterval(async () => {
                context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
                const predictions = await model.estimateFaces(context.canvas, false);

                if (predictions.length === 1) {
                    const face = predictions[0];
                    const x = face.topLeft[0];
                    const y = face.topLeft[1];
                    const width = face.bottomRight[0] - x;
                    const height = face.bottomRight[1] - y;
                    const frameRect = faceFrame.getBoundingClientRect();
                    const videoRect = video.getBoundingClientRect();

                    // Transform face coordinates relative to the video element
                    const scaleX = video.videoWidth / videoRect.width;
                    const scaleY = video.videoHeight / videoRect.height;
                    const transformedX = x / scaleX;
                    const transformedY = y / scaleY;
                    const transformedWidth = width / scaleX;
                    const transformedHeight = height / scaleY;

                    if (
                        transformedX > frameRect.left - videoRect.left && transformedY > frameRect.top - videoRect.top &&
                        transformedX + transformedWidth < frameRect.right - videoRect.left &&
                        transformedY + transformedHeight < frameRect.bottom - videoRect.top
                    ) {
                        faceStatus.textContent = 'Face detected';
                        faceStatus.style.color = 'green';
                        captureButton.disabled = false;
                    } else {
                        faceStatus.textContent = 'Face not in frame';
                        faceStatus.style.color = 'red';
                        captureButton.disabled = true;
                    }
                } else {
                    faceStatus.textContent = predictions.length > 1 ? 'Only 1 face allowed' : 'Face not detected';
                    faceStatus.style.color = 'red';
                    captureButton.disabled = true;
                }
            }, 100);
        }

        captureButton.addEventListener('click', async () => {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            const dataUrl = canvas.toDataURL('image/jpeg');
        
            const response = await fetch('/capture', {
                method: 'POST',
                body: JSON.stringify({ image: dataUrl }),
                headers: { 'Content-Type': 'application/json' }
            });
        
            const result = await response.json();
            if (result.success) {
                window.location.href = '/';  // Redirect to index.html
            } else {
                alert('Failed to capture image');
            }
        });
        

        setupCamera();
        detectFaces();
    </script>
</body>
</html>
